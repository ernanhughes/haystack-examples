{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import json\n",
    "\n",
    "from typing import List, Optional\n",
    "from haystack import Pipeline, component\n",
    "\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.retrievers import InMemoryBM25Retriever\n",
    "from haystack.components.writers import DocumentWriter\n",
    "\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.document_stores.types import DuplicatePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "\n",
    "@component\n",
    "class QueryExpander:\n",
    "\n",
    "    def __init__(self, prompt: Optional[str] = None, model: str = \"llama3.2\"):\n",
    "\n",
    "        self.query_expansion_prompt = prompt\n",
    "        self.model = model\n",
    "        if prompt == None:\n",
    "          self.query_expansion_prompt = \"\"\"\n",
    "          You are part of an information system that processes users queries.\n",
    "          You expand a given query into {{ number }} queries that are similar in meaning.\n",
    "          \n",
    "          Structure:\n",
    "          Follow the structure shown below in examples to generate expanded queries.\n",
    "          Examples:\n",
    "          1. Example Query 1: \"climate change effects\"\n",
    "          Example Expanded Queries: [\"impact of climate change\", \"consequences of global warming\", \"effects of environmental changes\"]\n",
    "          \n",
    "          2. Example Query 2: \"\"machine learning algorithms\"\"\n",
    "          Example Expanded Queries: [\"neural networks\", \"clustering\", \"supervised learning\", \"deep learning\"]\n",
    "          \n",
    "          Your Task:\n",
    "          Query: \"{{query}}\"\n",
    "          Example Expanded Queries:\n",
    "          \"\"\"\n",
    "        builder = PromptBuilder(self.query_expansion_prompt)\n",
    "        llm = OllamaGenerator(model = self.model)\n",
    "        self.pipeline = Pipeline()\n",
    "        self.pipeline.add_component(name=\"builder\", instance=builder)\n",
    "        self.pipeline.add_component(name=\"llm\", instance=llm)\n",
    "        self.pipeline.connect(\"builder\", \"llm\")\n",
    "\n",
    "    @component.output_types(queries=List[str])\n",
    "    def run(self, query: str, number: int = 5):\n",
    "        result = self.pipeline.run({'builder': {'query': query, 'number': number}})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Example Expanded Queries:\\n\\n[\"open source natural language processing frameworks\", \"free machine learning libraries for NLP\", \"public domain NLP tools and models\", \"community-driven NLP software libraries\"]']\n",
      "Example Expanded Queries:\n",
      "\n",
      "[\"open source natural language processing frameworks\", \"free machine learning libraries for NLP\", \"public domain NLP tools and models\", \"community-driven NLP software libraries\"]\n"
     ]
    }
   ],
   "source": [
    "expander = QueryExpander()\n",
    "text= expander.run(query=\"open source nlp frameworks\", number=4)\n",
    "\n",
    "print(text['llm']['replies'])\n",
    "text  = text['llm']['replies'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Expanded Queries:\n",
      "\n",
      "[\"open source natural language processing frameworks\", \"free machine learning libraries for NLP\", \"public domain NLP tools and models\", \"community-driven NLP software libraries\"]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['open source natural language processing frameworks', 'free machine learning libraries for NLP', 'public domain NLP tools and models', 'community-driven NLP software libraries']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Regular expression to extract the list items\n",
    "pattern = r'\\[\"([^\"]+)\", \"([^\"]+)\", \"([^\"]+)\", \"([^\"]+)\"\\]'\n",
    "\n",
    "# Find the match\n",
    "match = re.search(pattern, text)\n",
    "\n",
    "# Extract and print the list items if a match is found\n",
    "if match:\n",
    "    items = match.groups()\n",
    "    print(list(items))\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m pattern = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExpanded Queries:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m[[^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m]]*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m])\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Find all matches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m matches = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOTALL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Print the extracted lists\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\re\\__init__.py:216\u001b[39m, in \u001b[36mfindall\u001b[39m\u001b[34m(pattern, string, flags)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfindall\u001b[39m(pattern, string, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    209\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[32m    210\u001b[39m \n\u001b[32m    211\u001b[39m \u001b[33;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m \n\u001b[32m    215\u001b[39m \u001b[33;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags).findall(string)\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'dict'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# text = \"\"\"{'queries': ['Here are the expanded queries:\\\\n\\\\n1. \"open source nlp frameworks\"\\\\nExpanded Queries:\\\\n[\"open source natural language processing tools\", \"free nlp libraries for python\", \"open source machine learning nlp frameworks\", \"nlp open source software\"]\\\\n\\\\n2. \"machine learning algorithms\"\\\\nExpanded Queries:\\\\n[\"neural networks for classification\", \"decision trees in machine learning\", \"random forests for regression\", \"support vector machines\"]\\\\n\\\\n3. \"data science courses online\"\\\\nExpanded Queries:\\\\n[\"online data science certifications\", \"free data science tutorials\", \"data science boot camps with certification\", \"online courses for data science with hands on experience\"]',\n",
    "#   ['open source nlp frameworks']]}\"\"\"\n",
    "\n",
    "# Regular expression to extract the expanded queries lists\n",
    "pattern = r'Expanded Queries:\\\\n(\\[[^\\]]*\\])'\n",
    "\n",
    "# Find all matches\n",
    "matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "# Print the extracted lists\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
